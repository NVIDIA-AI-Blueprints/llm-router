# LLM Router Helm deployment sample configuration
# Copy this file to values.override.yaml and fill in your specific values

# Set your NVIDIA API key if you're using NVIDIA AI Foundation Models
apiKeys:
  nvidia_api_key: "YOUR_NVIDIA_API_KEY_HERE"  # Replace with your actual NVIDIA API key

# Use your preferred storage class and registry
global:
  storageClass: "YOUR_STORAGE_CLASS"  # e.g., "standard", "microk8s-hostpath"
  imageRegistry: "YOUR_REGISTRY/"     # e.g., "localhost:32000/", "docker.io/"

# Ingress configuration (optional - enables external access via domain names)
# Uncomment and configure if you want to access services via ingress
# ingress:
#   enabled: true
#   hosts:
#     - host: llm-router.local  # Change to your domain
#       # paths are pre-configured in values.yaml with working defaults

# Router Server
routerServer:
  enabled: true
  image:
    repository: router-server
    tag: latest
    pullPolicy: IfNotPresent
  resources:
    limits:
      nvidia.com/gpu: 1
      memory: "8Gi"
    requests:
      nvidia.com/gpu: 1
      memory: "8Gi"
  volumes:
    modelRepository:
      enabled: true
      mountPath: /model_repository
      hostPath: "/path/to/your/model/repository"  # Replace with your model repository path
  command: ["tritonserver", "--log-verbose=1", "--model-repository=/model_repository"]
  service:
    type: ClusterIP
  shm_size: "8G"

# Router Controller
routerController:
  enabled: true
  image:
    repository: router-controller
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP

# App 
app:
  enabled: true
  image:
    repository: llm-router-client
    tag: app
    pullPolicy: IfNotPresent
  volumes:
    appDir:
      enabled: true
      mountPath: /app
      hostPath: "/path/to/your/app/directory"  # Replace with your app directory path
  command: ["python", "app.py"]
  service:
    type: ClusterIP  

# Example endpoints when ingress is enabled:
# - App: http://llm-router.local/app/
# - Router Controller API: http://llm-router.local/router-controller/
# - Router Controller Health: http://llm-router.local/router-controller/health
# - Router Controller Config: http://llm-router.local/router-controller/config
# - Router Controller Metrics: http://llm-router.local/router-controller/metrics
# - Router Server Metrics: http://llm-router.local/router-server/ 